{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Best Practices\n",
    "\n",
    "#### Always do the next simplest test case\n",
    "\n",
    "- Gradually increase the complexity as you go, and continuously refactor\n",
    "- Keeps code clean\n",
    "- When you jump to a complex test case too quickly, you can end up writing a lot of production code at once\n",
    "    - We aim to maintain a short feedback cycle\n",
    "    - This can also lead to suboptimal design decisions\n",
    "    \n",
    "#### Always use descriptive test names\n",
    "\n",
    "- Since code is usually read many more times than it's written, it should be as readable as possible\n",
    "- Tests are the ideal documentation for how code works\n",
    "    - They should be easy to understand\n",
    "    \n",
    "#### Keep tests fast\n",
    "\n",
    "- They shouldn't take long to run\n",
    "    - We want to know immediately how our code has changed things\n",
    "- Console output should be kept to a minimum\n",
    "- Using mock objects are a faster alternative to collaborators\n",
    "\n",
    "#### Use code coverage analysis tools\n",
    "\n",
    "- Once unit tests are implemented, it's best to go back and run a code coverage tool\n",
    "    - This identifies any test cases we may have missed\n",
    "    - The goal is 100% code coverage\n",
    "    \n",
    "#### Run unit tests multiple times, and in random order\n",
    "\n",
    "- It is possible that some tests will pass sometimes and fail others\n",
    "    - Running them multiple times checks for this behaviour\n",
    "- By running the tests in random order, we test for any order dependency between them\n",
    "- Using the `pytest-random-order` and `pytest-repeat` make it easy\n",
    "\n",
    "#### Use a static code analysis tool\n",
    "\n",
    "- [pylint](https://www.pylint.org/) is best for this"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "____\n",
    "\n",
    "# Hands-on Example of Applying Best Practices\n",
    "\n",
    "#### Example 1: sometimes our test will pass, and other times it will fail\n",
    "\n",
    "- In our first example, we have a unit test that returns a random number between 1 and 100 \n",
    "    - If the number is even, the test will pass\n",
    "        - If it's is odd, it will fail"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```python\n",
    "import random\n",
    "\n",
    "def test_random_number():\n",
    "    random.seed()\n",
    "    rand_int = random.randint(1, 100)\n",
    "    assert rand_int % 2 == 0\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- We can configure Pycharm to use `pytest-repeat` to run each test multiple times"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Example 2: our second test depends on the first\n",
    "\n",
    "- In our code, both tests access a global `test_value` variable in the `TestVariables` module\n",
    "    - The `TestVariables.py` script is shown below\n",
    "    \n",
    "```python\n",
    "global test_value\n",
    "test_value = 0\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Now, our tests are:\n",
    "\n",
    "```python\n",
    "import TestVariables\n",
    "\n",
    "def test_one():\n",
    "    # Setting the global test_value variable to 1\n",
    "    TestVariables.test_value = 1\n",
    "    assert True\n",
    "    \n",
    "def test_two():\n",
    "    assert TestVariables.test_value == 1\n",
    "```\n",
    "\n",
    "- If we run `test_one` first, then `test_two`, both will pass\n",
    "    - However, if we run `test_two` first, it will fail\n",
    "        - This is because our `TestVariables` module sets `test_value = 0`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- We can configure Pycharm to use `pytest-random-order` to run these two tests in both orders"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "____\n",
    "\n",
    "# Overview of Code Coverage and `pytest-cov`\n",
    "\n",
    "#### What is code coverage analysis?\n",
    "\n",
    "- As we run our tests, the code coverage tool keeps track of the sections of our production code that are run\n",
    "- The coverage report tells us if there are any sections that aren't being tested\n",
    "- Ideally, we should have 100% code coverage\n",
    "\n",
    "#### Types of code coverage analysis\n",
    "\n",
    "1. Line\n",
    "    - This tells us which of the lines of code were run\n",
    "2. Statement\n",
    "    - This tells us which individual statements were run\n",
    "        - This include multiple statements on the same line\n",
    "3. Branch\n",
    "    - This tells us the paths of the code that were executed\n",
    "        - E.g. if we have an if statement, it checks whether both the True and False options were tested\n",
    "4. Modified Condition/Decision\n",
    "    - The most sophisticated version\n",
    "    - Extension of Branch coverage\n",
    "    - Tells us which criteria combinations were tested"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### `pytest-cov`\n",
    "\n",
    "- Easy to use plugin for Pycharm"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
